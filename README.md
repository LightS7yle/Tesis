# Informaci√≥n
Se ha implementado tres diferentes maneras de utilizar la implementaci√≥n Phi-4 mini + RAG en esta tesis, con el objetivo de comparar estas tres propuestas y elegir la mejor

1.- Implementaci√≥n original LLM ( Phi-4 mini ) sin RAG

2.- Implementaci√≥n de LLM ( Phi-4 mini ) con RAG

3.- Implementaci√≥n de LLM ( Phi-4 mini ) con RAG utilizando Document Refinement with Sentence-Level Re-ranking and Reconstruction to Enhance Retrieval-Augmented Generation (DSLR)

# Configuraci√≥n

### Notebooks

Todas las implementaciones en notebooks son en su mayor√≠a autoexplicativas y se encuentran comentadas.

Consta de 6 secciones:

1. Instalaci√≥n y configuraci√≥n de paquetes (requirements.txt)
```bash
pip install -r requirements.txt
```

2. Bloque de c√≥digo extracci√≥n de data de manuales (crear en el directorio de trabajo la carpeta Manuales y agregar los limites de inicio y fin por Manual agregado)

3. Bloque de c√≥digo de limpieza y preprocesamiento de datos / Generaci√≥n de embeddings

4. Bloque principal de c√≥digo con documentaci√≥n Phi-4 mini / Phi-4 mini + RAG / Phi-4 mini + RAG + DSLR

5. Ejemplo de inferencia con 4 manuales operativos

6. M√©tricas de evaluaci√≥n ROUGE / BERTSCORE / FRANQ

Nota-1 : Por temas de privacidad y confidencialidad de la informaci√≥n de la empresa no se ha subido al repositorio los manuales operativos en PDF 

Nota-2 : En caso querer probar el c√≥digo del notebook "analisis.ipynb" solicitar por interno los manuales

Nota-3 : No habr√° problema en probar el c√≥digo descrito en el punto 4 ("LLM.ipynb") ya que los embeddings y metadatos de los manuales ya fueron extraidos

Nota-4 : La data QA se obtuvo a partir de los chunks generados en "chunks_para_qa.csv" usando un LLM como GPT-4

# Correr Notebooks

Primero hacer las configuraciones descritas anteriormente

Segundo ejecutar analisis.ipynb para obtener los embedding de tus manuales

Tercero ejecutar LLM.ipynb para guardar las inferencias generadas por los diferentes modelos descritos anteriormente.

Cuarto ejecutar evaluacion.ipynb para generar los cuadros comparativos entre los diferentes modelos.

# Trabajo futuro

Se buscar√° aplicar otros m√©todos para generaci√≥n de embeddings diferente al usado ("distiluse-base-multilingual-cased-v1") como lo es el Node2Vec, ganando conectar 

informaci√≥n entre manuales por su estructura t√©cnica y relacional generando un grafo de conocimiento

Es decir, cuando un operario realiza una consulta:

B√∫squeda sem√°ntica (texto): Se recupera chunks que se parecen en el texto a la consulta (FAISS)

B√∫squeda estructural (grafo con Node2Vec): Se recupera manuales/nodos que est√°n relacionados en la red con los resultados de la busqueda sem√°ntica

Ejemplo: Preguntan ‚Äúprocedimiento de calibraci√≥n de v√°lvula‚Äù

El texto trae el Manual A (v√°lvulas).

Pero gracias al grafo, tambi√©n se trae el Manual B (bombas), porque est√° estructuralmente vinculado en el sistema (comparten el mismo proveedor de v√°lvulas/bombas)

Posibilidad de combinaci√≥n de resultados texto + grafos:

Concatenaci√≥n embeddings (texto + grafo)

Es decir, el LLM ya no responde solo lo m√°s cercano a la consulta vectorialmente, sino con ‚Äúlo m√°s parecido en palabras y en relaciones t√©cnicas‚Äù.

---

## üìà Resultados esperados (Semana 3)
- **EDA inicial** en `notebooks/analisis.ipynb`.  
- **Baseline Dummy** (LLM Phi-4 mini) ‚Üí Bertscore F1 ‚âà 0.834 pero sin RAG.  
- **M√©trica central**: Bertscore ‚âà 0.852 utilizando Phi-4 mini + RAG + DSLR
- **Logs de resultados** ‚Üí `logs/metrics_baseline.txt`.  
- **Slides de resultados** ‚Üí generados con `evaluacion.ipynb`  
---

# Autor
Diego Fernando L√≥pez Lozano
