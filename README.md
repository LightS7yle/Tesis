# InformaciÃ³n
Se ha implementado tres diferentes maneras de utilizar la implementaciÃ³n Phi-4 mini + RAG en esta tesis, con el objetivo de comparar estas tres propuestas y elegir la mejor

1.- ImplementaciÃ³n original LLM ( Phi-4 mini ) sin RAG

2.- ImplementaciÃ³n de LLM ( Phi-4 mini ) con RAG

3.- ImplementaciÃ³n de LLM ( Phi-4 mini ) con RAG utilizando Document Refinement with Sentence-Level Re-ranking and Reconstruction to Enhance Retrieval-Augmented Generation (DSLR)

---

## ğŸ“Š Dataset
- **Fuente**: Empresa Privada de GeneraciÃ³n de EnergÃ­a ElÃ©ctrica 
- **Registros**: 5 manuales  
- **Variables**: pÃ¡ginas, idioma, formato  
- **VersiÃ³n usada**: descargada el 20/09/2025  

---

## ğŸ—‚ï¸ Estructura del repositorio
```
Tesis/
  â”œâ”€â”€  .env
  â”œâ”€â”€  .gitignore
  â”œâ”€â”€  README.md
  â”œâ”€â”€  requirements.txt
  â”œâ”€â”€  temp.txt    
dataQA/
  â”œâ”€â”€  qa.csv                                               # Archivo preguntas/respuestas SH / respuestas modelos
  â”œâ”€â”€  qa.txt                                               # Archivo preguntas/respuestas obtenido con el apoyo de los stakeholders (SH)
ManualesDummy/
  â”œâ”€â”€  7.5 RO FOULING substance (anaysis solution).pdf
  â”œâ”€â”€  Manual de Turbina TG-1 Kallpa.pdf
  â”œâ”€â”€  MANUAL Y USO DE BOMBAS OBL SERIE R.pdf
  â”œâ”€â”€  PD-0100-0001_Rev_m.pdf
  â”œâ”€â”€  SB4-14-0055-GT-EN-01.pdf
  â”œâ”€â”€  SB4-17-0022-GT-EN-01.pdf
  â”œâ”€â”€  SB4-18-0104-GT-EN-01.pdf
  â”œâ”€â”€  SB4-19-0009-GT-EN-01.pdf
  â”œâ”€â”€  SB5-08-0021-GT-EN-01.pdf
  â”œâ”€â”€  sd31_manual.pdf
notebooks/
  â”œâ”€â”€  analisis.ipynb                                        # AnÃ¡lisis exploratorio inicial
  â”œâ”€â”€  evaluacion.ipynb                                      # EvaluaciÃ³n de resultados
  â”œâ”€â”€  LLM.ipynb
  â”œâ”€â”€  LLM_gemma.ipynb                                          # Libro principal LLM / LLM + RAG / LLM + RAG + DSLR
outputs/
  â”œâ”€â”€  chunks_para_qa.csv                                    # Chunks de todos los manuales
  â”œâ”€â”€  embeddings_y_metadatos.pkl
  â”œâ”€â”€  faiss_index.index
  â”œâ”€â”€  embeddings_gemma_y_metadatos.pkl                      # Sentence embedding generado por Gemma     
  â”œâ”€â”€  df_qa.csv                                             # En este .csv se guardan las respuestas generadas por mi modelo para mÃ©tricas 
resultados/                                                  # Resultados comparando mis 3 alternativas: LLM / LLM + RAG / LLM + RAG + DSLR
  â”œâ”€â”€  evaluacion_con_bert.csv                           
  â”œâ”€â”€  evaluacion_con_rouge.csv
  â”œâ”€â”€  evaluacion_rag_con_bert.csv
  â”œâ”€â”€  evaluacion_rag_con_franq.csv
  â”œâ”€â”€  evaluacion_rag_con_rouge.csv
  â”œâ”€â”€  evaluacion_rag_dslr_con_bert.csv
  â”œâ”€â”€  evaluacion_rag_dslr_con_rouge.csv
  â”œâ”€â”€  Comparativa_resultados.xlsx     
\
```

---

# ConfiguraciÃ³n

### Notebooks

Todas las implementaciones en notebooks son en su mayorÃ­a autoexplicativas y se encuentran comentadas.

Consta de 6 secciones:

1. InstalaciÃ³n y configuraciÃ³n de paquetes (requirements.txt)
```bash
pip install -r requirements.txt
```

2. Bloque de cÃ³digo extracciÃ³n de data de manuales (crear en el directorio de trabajo la carpeta Manuales y agregar los limites de inicio y fin por Manual agregado)

3. Bloque de cÃ³digo de limpieza y preprocesamiento de datos / GeneraciÃ³n de embeddings

4. Bloque principal de cÃ³digo con documentaciÃ³n Phi-4 mini / Phi-4 mini + RAG / Phi-4 mini + RAG + DSLR

5. Ejemplo de inferencia con 4 manuales operativos

6. MÃ©tricas de evaluaciÃ³n ROUGE / BERTSCORE / FRANQ

Nota-1 : Por temas de privacidad y confidencialidad de la informaciÃ³n de la empresa no se ha subido al repositorio los manuales operativos en PDF 

Nota-2 : En caso querer probar el cÃ³digo del notebook "analisis.ipynb" solicitar por interno los manuales

Nota-3 : No habrÃ¡ problema en probar el cÃ³digo descrito en el punto 4 ("LLM.ipynb") ya que los embeddings y metadatos de los manuales ya fueron extraidos

Nota-4 : La data QA se obtuvo a partir de los chunks generados en "chunks_para_qa.csv" usando un LLM como GPT-4

# Correr Notebooks

Primero hacer las configuraciones descritas anteriormente

Segundo ejecutar analisis.ipynb para obtener los embedding de tus manuales

Tercero ejecutar LLM.ipynb para guardar las inferencias generadas por los diferentes modelos descritos anteriormente.

Cuarto ejecutar evaluacion.ipynb para generar los cuadros comparativos entre los diferentes modelos.

---

## ğŸ“ˆ Resultados esperados (Semana 3)
- **EDA inicial** en `notebooks/analisis.ipynb`.  
- **Baseline Dummy** (LLM Phi-4 mini) â†’ Bertscore F1 â‰ˆ 0.834 pero sin RAG.  
- **MÃ©trica central**: Bertscore â‰ˆ 0.852 utilizando Phi-4 mini + RAG + DSLR
- **Logs de resultados** â†’ `/resultados/Comparativa_resultados.xlsx`.  
- **Slides de resultados** â†’ generados con `evaluacion.ipynb`  
---


# Trabajo futuro

Se buscarÃ¡ aplicar otros mÃ©todos para generaciÃ³n de embeddings diferente al usado ("distiluse-base-multilingual-cased-v1") como lo es el Node2Vec, ganando conectar informaciÃ³n entre manuales por su estructura tÃ©cnica y relacional generando un grafo de conocimiento

Es decir, cuando un operario realiza una consulta:

BÃºsqueda semÃ¡ntica (texto): Se recupera chunks que se parecen en el texto a la consulta (FAISS)

BÃºsqueda estructural (grafo con Node2Vec): Se recupera manuales/nodos que estÃ¡n relacionados en la red con los resultados de la busqueda semÃ¡ntica

Ejemplo: Preguntan â€œprocedimiento de calibraciÃ³n de vÃ¡lvulaâ€

El texto trae el Manual A (vÃ¡lvulas).

Pero gracias al grafo, tambiÃ©n se trae el Manual B (bombas), porque estÃ¡ estructuralmente vinculado en el sistema (comparten el mismo proveedor de vÃ¡lvulas/bombas)

Posibilidad de combinaciÃ³n de resultados texto + grafos:

ConcatenaciÃ³n embeddings (texto + grafo)

Es decir, el LLM ya no responde solo lo mÃ¡s cercano a la consulta vectorialmente, sino con â€œlo mÃ¡s parecido en palabras y en relaciones tÃ©cnicasâ€.

# ğŸ‘¥ Autor
Diego Fernando LÃ³pez Lozano
